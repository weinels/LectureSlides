\documentclass{beamer}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[inline]{asymptote}
\usepackage{slide_helper}
\usepackage{caption}
\usepackage{subcaption}

\title[MATH 2250 - Section 5.2]{Properties of Linear Transformations}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}[fragile]
\begin{block}{Injectivity}
A function $\mapping{f}{\mathbb{X}}{\mathbb{Y}}$ is \textbf{one-to-one}, or \textbf{injective}, provided that $f(u)=f(v)$ implies $u=v$.
\end{block}\pause
\begin{block}{}
\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.45\textwidth}
\centering
\begin{asy}
import graph;
import fontsize;
defaultpen(fontsize(9pt));
size(130);
ngraph=1000;
real min_x=-1, max_x=1;
real min_y=-1, max_y=1;

pair start=(min_x,min_y);
pair end=(max_x,max_y);

real f(real x) {return x*x*x;}

draw(graph(f ,min_x, max_x),black+0.5bp);

draw((0.75,0) -- (0.75,f(0.75)),dashed+blue+0.5bp);
draw((0.75,f(0.75)) -- (0.0,f(0.75)),dashed+blue+0.5bp);

draw((-0.75,0) -- (-0.75,f(-0.75)),dashed+blue+0.5bp);
draw((-0.75,f(-0.75)) -- (0.0,f(-0.75)),dashed+blue+0.5bp);

limits(start,end,Crop);

xaxis("$x$",YEquals(0),min_x,max_x,NoTicks(), Arrows());
yaxis("$y$",XEquals(0),min_y,max_y,NoTicks(), Arrows());
\end{asy}
\caption{$f(x)=x^3$ is injective}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
\centering
\begin{asy}
import graph;
import fontsize;
defaultpen(fontsize(9pt));
size(130);
ngraph=1000;
real min_x=-1, max_x=1;
real min_y=-1, max_y=1;

pair start=(min_x,min_y);
pair end=(max_x,max_y);

real f(real x) {return x*x;}

draw(graph(f ,min_x, max_x),black+0.5bp);

draw((0.75,0) -- (0.75,f(0.75)),dashed+blue+0.5bp);
draw((0.75,f(0.75)) -- (0.0,f(0.75)),dashed+blue+0.5bp);

draw((-0.75,0) -- (-0.75,f(-0.75)),dashed+blue+0.5bp);
draw((-0.75,f(-0.75)) -- (0.0,f(-0.75)),dashed+blue+0.5bp);

limits(start,end,Crop);

xaxis("$x$",YEquals(0),min_x,max_x,NoTicks(), Arrows());
yaxis("$y$",XEquals(0),min_y,max_y,NoTicks(), Arrows());
\end{asy}
\caption{$g(x)=x^2$ is not injective}
\end{subfigure}
\end{figure}
\end{block}
\end{frame}

\begin{frame}[fragile]
\begin{block}{Surjectivity}
The set of output values of a function $\mapping{f}{\mathbb{X}}{\mathbb{Y}}$ is a subset of the codomain $\mathbb{Y}$ and is called the \textbf{image} of the function. If the image is all of $\mathbb{Y}$, the function $f$ is said to map \textbf{onto} $\mathbb{Y}$, or to be \textbf{surjective}.
\end{block}\pause
\begin{block}{}
\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.45\textwidth}
\centering
\begin{asy}
import graph;
import fontsize;
defaultpen(fontsize(9pt));
size(130);
ngraph=1000;
real min_x=-1, max_x=1;
real min_y=-1, max_y=1;

pair start=(min_x,min_y);
pair end=(max_x,max_y);

real f(real x) {return -1*x;}

draw(graph(f ,min_x, max_x),black+0.5bp);

limits(start,end,Crop);

xaxis("$x$",YEquals(0),min_x,max_x,NoTicks(), Arrows());
yaxis("$y$",XEquals(0),min_y,max_y,NoTicks(), Arrows());
\end{asy}
\caption{$f(x)=-x$ is surjective}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
\centering
\begin{asy}
import graph;
import fontsize;
defaultpen(fontsize(9pt));
size(130);
ngraph=1000;
real min_x=-1, max_x=1;
real min_y=-1, max_y=1;

pair start=(min_x,min_y);
pair end=(max_x,max_y);

real f(real x) {return abs(x);}

draw(graph(f ,min_x, max_x),black+0.5bp);

limits(start,end,Crop);

xaxis("$x$",YEquals(0),min_x,max_x,NoTicks(), Arrows());
yaxis("$y$",XEquals(0),min_y,max_y,NoTicks(), Arrows());
\end{asy}
\caption{$g(x)=\abs{x}$ is not surjective}
\end{subfigure}
\end{figure}
\end{block}
\end{frame}

\begin{frame}
\begin{example}
The linear transformation $\mapping{T}{\R^2}{\R^3}$ defined by $T(\vect{v})=\mat{A}\vect{v}$ where
\begin{equation*}
\mat{A}=
\begin{bmatrix}[rr]
1 & 1 \\
1 & -1 \\
2 & 1 \\
\end{bmatrix}\pause
\quad\Rightarrow\quad
\mat{A}\vect{v}=
\begin{bmatrix}[rr]
1 & 1 \\
1 & -1 \\
2 & 1 \\
\end{bmatrix}
\bvector{v_1,v_2}=
\bvector{v_1+v_2, v_1-v_2, 2v_1+v_2}
\end{equation*}\pause
What is the image of $T$?\pause
\begin{equation*}
\vect{u}=v_1\bvector{1,1,2}+v_2\bvector{\+1,-1,\+1}\pause
\quad\Rightarrow\quad
\bvector{1,1,2}\text{ and }\bvector{\+1,-1,\+1}\text{ are independent.}
\end{equation*}
So, $\Col\mat{A}$, the column space of $\mat{A}$, is the image of $T$.\pause

\vspace{2mm}
We can derive the equation of this plane by looking at the system

\vspace{-4mm}
\begin{equation*}
u_1=v_1+v_2,\quad
u_2=v_1-v_2,\quad
u_3=2v_1+v_2
\end{equation*}\pause

\vspace{-6mm}
Eliminating $v_1$ and $v_2$ gives us

\vspace{-4mm}
\begin{equation*}
3u_1+u_2-2u_3=0
\end{equation*}
\end{example}
\end{frame}

\begin{frame}
\begin{block}{Image Theorem}
Let $\mapping{T}{\V}{\W}$ be a linear transformation from vector space $\V$ to vector space $\W$ with image $\im(T)$. Then:
\onslide<+->
\begin{itemize}[<+- | alert@+>]
\item $\im(T)$ is a subspace of $\W$.
\item $T$ is surjective if and only is $\im(T)=\W$.
\end{itemize}
\end{block}
\onslide<+->
\begin{block}{Rank of a Linear Transformation}
The dimension of the image of a linear transformation $T$ is called its \textbf{rank}
\begin{equation*}
\rank(T)=\dim(\im(T))
\end{equation*}
\end{block}
\end{frame}

\begin{frame}
\begin{example}
For $\mapping{T}{\R^4}{\R^2}$ defined by

\vspace{-6mm}
\begin{equation*}
T(\vect{v})=\mat{A}\vect{v}=
\begin{bmatrix}[rrrr]
2 & -4 & 3 & 6 \\
-1 & 2 & -2 & -3 \\
\end{bmatrix}
\bvector{v_1,v_2,v_3,v_4}=\vect{w}
\end{equation*}\pause

\vspace{-6mm}
We can write

\vspace{-1mm}
\begin{equation*}
\vect{w}=v_1 \bvector{\+2,-1} + v_2 \bvector{-4,\+2} + v_3 \bvector{\+3,-2} + v_4 \bvector{\+6,-3}
\end{equation*}\pause

\vspace{-6mm}
Which means 

\vspace{-1mm}
\begin{equation*}
\im(T)=\spn\left\{\bvector{\+2,-1}, \bvector{-4,\+2}, \bvector{\+3,-2}, \bvector{\+6,-3}\right\}
\end{equation*}
which is a subset of $\R^2$.\pause To determine the dimension we need to determine how many pivot columns $\mat{A}$ has:

\vspace{-2mm}
\begin{equation*}
\begin{bmatrix}[rrrr]
2 & -4 & 3 & 6 \\
-1 & 2 & -2 & -3 \\
\end{bmatrix}\pause
\quad\rightarrow\quad
\begin{bmatrix}[rrrr]
1 & -2 & 0 & 3 \\
0 & 0 & 1 & 0 \\
\end{bmatrix}
\end{equation*}

\vspace{-3mm}
Thus, $\rank(T)=\dim(\im(T))=\dim(\Col\mat{A})=2$.
\end{example}
\end{frame}

\begin{frame}
\begin{block}{Rank of a Matrix Multiplication Operator}
For any linear transformation $\mapping{T}{\R^n}{\R^m}$ defined by $T(\vect{x})=\mat{A}\vect{x}$, where $\mat{A}\in\M_{mn}$ and $\vect{x}\in\V$, the image of $T$ is the column space of $A$. (Thats is, $\im(T)=\Col\mat{A}$.) 

\vspace{2mm}
The pivot columns of $A$ form a basis for $\im(T)$.

\vspace{2mm}
Consequently,
\begin{equation*}
\begin{aligned}
\rank(T) &= \dim(\im(T))\\
		 &= \dim(\Col\mat{A})\\
		 &= \text{The number of pivot columns in $\mat{A}$.}
\end{aligned}
\end{equation*}
\end{block}\pause
\begin{block}{Reminder}
The basis of $\Col\mat{A}$ must come from $\mat{A}$, \emph{not} from the RREF of $\mat{A}$.
\end{block}
\end{frame}

\begin{frame}
\begin{block}{}
Recall that a linear transformation $\mapping{T}{\V}{\W}$ must map the zero vector of $\V$ to the zero vector of $\W$.
\end{block}\pause
\begin{block}{Kernel of a Linear Transformation}
The \textbf{kernel} (or \textbf{nullspace}) of a linear transformation $\mapping{T}{\V}{\W}$, denoted $\ker(T)$, is the set of vectors in $\V$ that are mapped by $T$ to the zero vector of $\W$.
\begin{equation*}
\ker(T)=\setbuilder{\vect{v}\in\V}{T(\vect{v})=\vect{0}}
\end{equation*}
\end{block}\pause
\begin{example}
Consider the projection $\mapping{T}{\R^3}{\R^3}$ defined by
\begin{equation*}
T(x,y,z)=(x,y,0)
\end{equation*}
What is the kernel of $T$?\pause
\begin{equation*}
\ker(T)=\setbuilder{(0,0,z)}{z\in\R}
\end{equation*}
\end{example}
\end{frame}

\begin{frame}
\begin{example}
Consider the transformation $\mapping{T}{\R^3}{\R^2}$ defined by
\begin{equation*}
T(\vect{v})=\mat{A}\vect{v}=
\begin{bmatrix}
1 & 1 & 2 \\
2 & 3 & 5 \\
\end{bmatrix}
\bvector{v_1,v_2,v_3}=
\bvector{v_1+v_2+2v_3, 2v_1+3v_2+5v_3}
\end{equation*}
\pause

\vspace{-3mm}
To find the vectors that are mapped to $\vect{0}$, we have to solve the system:
\begin{equation*}
\begin{matrix}[llll]
\phantom{2}v_1&+\phantom{3}v_2&+2v_3 &= 0\\
2v_1&+3v_2&+5v_3 &= 0\\
\end{matrix}
\pause\quad\rightarrow\quad
\begin{bmatrix}[rrr|r]
1 & 1 & 2 & 0 \\
2 & 3 & 5 & 0 \\
\end{bmatrix}
\pause\quad\rightarrow\quad
\begin{bmatrix}[rrr|r]
1 & 0 & 1 & 0 \\
0 & 1 & 1 & 0 \\
\end{bmatrix}
\end{equation*}\pause
So, we see that $v_3$ is a free variable and if $v_3=s$ is a parameter, we have $v_1=-s$, $v_2=-s$, and $v_3=s$.\pause

\vspace{2mm}
Thus, the kernel is any scalar multiple of $<-1,-1,\+1>$:
\begin{equation*}
\ker(T)=\spn\left\{\bvector{-1,-1,\+1}\right\}
\end{equation*}
\end{example}
\end{frame}

\begin{frame}
\begin{example}
Consider the transformation $\mapping{T}{\R^2}{\R^2}$ defined by the matrix
\begin{equation*}A=
\begin{bmatrix}
1 & 1 \\
4 & 1 \\
\end{bmatrix}
\end{equation*}
What is the kernel of $T$?\pause

\vspace{2mm}
To find the kernel we need to solve $\mat{A}\vect{v}=\vect{0}$:
\begin{equation*}
\begin{bmatrix}
1 & 1 \\
4 & 1 \\
\end{bmatrix}
\bvector{v_1,v_2}=\bvector{0,0}
\pause\quad\rightarrow\quad
\begin{bmatrix}[rr|r]
1 & 1 & 0 \\
4 & 1 & 0 \\
\end{bmatrix}
\pause\quad\rightarrow\quad
\begin{bmatrix}[rr|r]
1 & 0 & 0 \\
0 & 1 & 0 \\
\end{bmatrix}
\end{equation*}\pause
Thus,
\begin{equation*}
\ker(T)=\{\vect{0}\}
\end{equation*}
\end{example}
\end{frame}

\begin{frame}
\begin{example}
Consider the transformation $\mapping{T}{\R^2}{\R^2}$ defined by the matrix
\begin{equation*}A=
\begin{bmatrix}
2 & 1 \\
2 & 1 \\
\end{bmatrix}
\end{equation*}
What is the kernel of $T$?\pause

\vspace{2mm}
To find the kernel we need to solve $\mat{A}\vect{v}=\vect{0}$:
\begin{equation*}
\begin{bmatrix}
2 & 1 \\
2 & 1 \\
\end{bmatrix}
\bvector{v_1,v_2}=\bvector{0,0}
\pause\quad\rightarrow\quad
\begin{bmatrix}[rr|r]
1 & 1 & 0 \\
1 & 1 & 0 \\
\end{bmatrix}
\pause\quad\rightarrow\quad
\begin{bmatrix}[rr|r]
1 & \tfrac{1}{2} & 0 \\
0 & 0 & 0 \\
\end{bmatrix}
\end{equation*}\pause
In this case we have $v_1=-\tfrac{1}{2}v_2$ and so, if we let our parameter be $v_2=s$ we have
\begin{equation*}
\ker(T)=\left\{s\bvector{-\tfrac{1}{2},\+1}\right\}
\end{equation*}
\end{example}
\end{frame}

\begin{frame}
\begin{example}
Consider the transformation $\mapping{T}{\R^2}{\R^2}$ defined by the matrix
\begin{equation*}A=
\begin{bmatrix}
0 & 0 \\
0 & 0 \\
\end{bmatrix}
\end{equation*}\pause
It should be clear that this transformation maps all vectors $\vect{v}\in\R^2$ to $\vect{0}$.\pause

\vspace{2mm}
Thus,
\begin{equation*}
\ker(T)=\R^2
\end{equation*}
\end{example}\pause
\begin{block}{}
These examples seem to suggest that the kernel of the linear transformation $\mapping{T}{\V}{\W}$ is a subspace of $\W$.
\end{block}
\end{frame}

\begin{frame}
\begin{block}{Kernel Theorem}
Let $\mapping{T}{\V}{\W}$ be a linear transformation from vector space $\V$ to vector space $\W$ with kernel $\ker(T)$.

\vspace{2mm}
Then,
\begin{enumerate}
\item\label{kerthm1} $\ker(T)$ is a subspace of $\V$.
\item\label{kerthm2} $T$ is injective if and only if $\ker(t)=\{\vect{0}\}$.
\end{enumerate}
\end{block}\pause
\begin{proof}
It is straightforward to verify~\enumref{kerthm1}, so let us prove~\enumref{kerthm2}.\pause

\vspace{1mm}
Suppose $T$ is injective, which means that $T(\vect{u})=T(\vect{v})$ implies $\vect{u}=\vect{v}$.\pause

\vspace{1mm}
Then, for $\vect{w}\in\ker(T)$, we have $T(\vect{w})=\vect{0}$.\pause

\vspace{1mm}
Which means $T(\vect{w})=T(\vect{0})$ and hence $\vect{w}=\vect{0}$.\pause\ Thus, $\ker(T)=\{\vect{0}\}$.\pause

\vspace{1mm}
Now, suppose that we know $\ker(T)=\{\vect{0}\}$.\pause

\vspace{1mm}
So $T(\vect{u})=T(\vect{v})$ implies $T(\vect{u})-T(\vect{v})=T(\vect{u}-\vect{v})=T(\vect{0})=\vect{0}$.\pause 

\vspace{1mm}
Thus, $\vect{u}-\vect{v}$ is in the kernel, which means $\vect{u}=\vect{v}$ and thus $T$ is injective.
\end{proof}
\end{frame}

\begin{frame}
\begin{example}
Consider the transformation $\mapping{T}{\R^4}{\R^2}$ defined by $T(\vect{v})=\mat{A}\vect{v}$, where
\begin{equation*}
\mat{A}=\begin{bmatrix}[rrrr]
 2 & -4 &  3 & 6 \\
-1 &  2 & -2 & -3 \\
\end{bmatrix}
\end{equation*}\pause
We can determine the kernel by solving the system:
\begin{equation*}
\begin{bmatrix}[rrrr|r]
2 & -4 & 3 & 6  & 0\\
-1 & 2 & -2 & -3 & 0 \\
\end{bmatrix}\pause
\quad\rightarrow\quad
\begin{bmatrix}[rrrr|r]
1 & -2 & 0 & 3 & 0\\
0 & 0 & 1 & 0 & 0\\
\end{bmatrix}
\end{equation*}\pause
So, we see that $v_1=2v_2-3v_4$ and $v_3=0$. If we let $v_2=r$ and $v_4=s$,
\begin{equation*}
\vect{v}
=\bvector{2r-3s,\phantom{0}r+0s,0r+0s,0r+\phantom{0}s}
=r\bvector{2,1,0,0}+s\bvector{-3,\+0,\+0,\+1}\pause
\ \rightarrow\ 
\ker(T)=\spn\left\{\bvector{2,1,0,0},\bvector{-3,\+0,\+0,\+1}\right\}
\end{equation*}
The dimension of the kernel of $T$ is 2.\pause

(Remember that the dimension of the image of $T$ was 2.)
\end{example}
\end{frame}

\begin{frame}
\onslide<+->
\begin{block}{Dimension Theorem}
Let $\mapping{T}{\V}{\W}$ be a linear transformation from a finite vector space $\V$.

\vspace{2mm}
Then
\begin{equation*}
\dim(\ker(T))+\dim(\im(T))=\dim(\V)
\end{equation*}
\end{block}
\onslide<+->
\begin{example}
From earlier examples:
\begin{itemize}[<+->]
\item $\mapping{T}{\R^3}{\R^3}$ defined by $T(x,y,z)=(x,y,0)$ had

\vspace{-3mm}
\begin{equation*}
\dim(\ker(T))+\dim(\im(T))=1+2=3=\dim(\R^3)
\end{equation*}
\item $\mapping{D_2}{\Poly_3}{\Poly_1}$ had

\vspace{-3mm}
\begin{equation*}
\ker(D_2)=\{cx+d\}
\quad\text{and}\quad
\im(D_2)=\{6ax+2b\}
\end{equation*}

\vspace{-3mm}
\begin{equation*}
\dim(\ker(D_2))+\dim(\im(D_2))=2+2=4=\dim(\Poly_3)
\end{equation*}
\end{itemize}
\end{example}
\end{frame}
\end{document}