\documentclass{beamer}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{tabu}
\usepackage[inline]{asymptote}
\usepackage{subcaption}
\usepackage{slide_helper}

\usepackage[customcolors, beamer]{hf-tikz}
\tikzset{style green/.style={
    set fill color=green!60!lime!50,
    set border color=green!60!lime!50,
  },
  style cyan/.style={
    set fill color=cyan!50!blue!40,
    set border color=cyan!50!blue!40,
  },
  style orange/.style={
    set fill color=orange!50!red!60,
    set border color=red!80,
  },
  hor/.style={
    above left offset={-0.0,0.35},
    below right offset={0.03,-0.15},
    #1
  },
  ver/.style={
    above left offset={-0.0,0.35},
    below right offset={0.05,-0.15},
    #1
  },
  ver2/.style={
    above left offset={-0.15,0.35},
    below right offset={0.15,-0.15},
    #1
  }
}

\begin{asydef}
import graph;
import fontsize;
defaultpen(fontsize(9pt));
ngraph=1000;

void draw_approx(int li, bool lbl=true)
{
	real a=0.746429;
	real b=0.565357;
	real f(real x) {return a*x+b;}
	real a=-0.080943178;
    real c=0.2409038;
    real b=1.130531112;
    real g(real x) {return a*x^2+b*x+c;}
    real a=0.30717;
    real b=-2.142883;
    real c=5.05044;
    real d=-1.749631;
    real h(real x) {return a*x^3+b*x^2+c*x+d;}
    real A=0.685989041;
    real B=0.43570003291;
    real i(real x) {return A*exp(B*x);}
    real min_x=0, max_x=4;
    real min_y=0, max_y=4;
    
    // draw data points
    
    dot((0.7,1.4),black);
    dot((0.9,0.5),black);
    dot((1.8,2.1),black);
    dot((2.0,2.9),black);
    dot((3.8,3.4),black);
    dot((2.6,1.9),black);
    
    // linear best-fit
    if (li >= 1)
	    draw(graph(f,min_x,max_x),red+1bp);
	    
	if (li >= 2)
	    draw(graph(g,min_x,max_x),blue+1bp);
	    
	if (li >= 3)
	    draw(graph(h,min_x,max_x),heavygreen+1bp);
	    
	if (li >= 4)
	    draw(graph(i,min_x,max_x),orange+1bp);
    
    limits((min_x-0.1,min_y-0.1),(max_x+0.1,max_y+0.1),Crop);
    
    for(real gx=min_x; gx<=max_x; gx+=0.5)
    	draw((gx,min_y)--(gx,max_y),dotted+darkgray);
        
    for(real gy=min_y; gy<=max_y; gy+=0.5)
    	draw((min_y,gy)--(max_x,gy),dotted+darkgray); 
    
    xaxis(YEquals(min_y),min_x,max_x,LeftTicks(NoZero));
    //xaxis(YEquals(min_y),min_x,max_x);
    yaxis(XEquals(min_x),min_y,max_y,RightTicks(NoZero));
    //yaxis(XEquals(min_x),min_y,max_y);
    
    // draw labels
    real base_x=3.5;
    real base_y=1.75;
    real step=-0.5;
    
    if (lbl)
    {
    	unfill(box((3,2),(4,2-(0.5*li))));
    
    	if (li >= 1)
	    	label("Linear",(base_x,base_y),red);
	    
		if (li >= 2)
	    	label("Quadratic",(base_x,base_y+step),blue);
	    
		if (li >= 3)
	    	label("Cubic",(base_x,base_y+(2*step)),heavygreen);
	    
		if (li >= 4)
	    	label("Exponential",(base_x,base_y+(3*step)),orange);
	}
}
\end{asydef}

\title[MATH 2250 - Section 3.4]{The Determinant of a Matrix}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}
\begin{block}{Determinant of a $2 \by 2$ Matrix}
The \textbf{determinant of a $2 \by 2$ matrix} is defined:
\begin{equation*}
\abs{\mat{A}} = 
\begin{vmatrix}
a & b \\
c & d
\end{vmatrix}
=ad-bc
\end{equation*}
\end{block}\pause
\begin{example}
\begin{equation*}
\begin{vmatrix}
\+3 & \+8\\
\+5 & -1
\end{vmatrix}
=3\cdot (-1) + 8\cdot 5=37
\end{equation*}
\end{example}
\end{frame}

\begin{frame}
\begin{block}{Minors of a Matrix}
For every element $a_{ij}$ of a $n \by n$ matrix $\mat{A}$, the \textbf{minor} $\mat{M_{ij}}$ is an $(n-1) \by (n-1)$ matrix obtained by deleting the $i$th row and the $j$th column of $\mat{A}$.
\end{block}\pause
\begin{example}
\begin{equation*}
\mat{A}=
\begin{bmatrix}
	\tikzmarkin<3>[hor=style green]{row-x}\+5 & \tikzmarkin<3>[ver=style green]{col-x}\+4 &  -3\tikzmarkend{row-x}\\
	\+2 &  -8 & \+1\\
	\+9 & \+3\tikzmarkend{col-x} & \+0\\
\end{bmatrix}
\qquad
\mat{M_{12}}=\pause
\begin{bmatrix}
		2 & 1\\
		9 & 0\\
\end{bmatrix}
\end{equation*}
\end{example}\pause
\begin{block}{Cofactors of a Matrix}
For every element $a_{ij}$ of a $n \by n$ matrix $\mat{A}$, the \textbf{cofactor} of $a_{ij}$ is the scalar
\begin{equation*}
C_{ij}={(-1)}^{(i+j)}\abs{\mat{M_{ij}}}
\end{equation*}
\end{block}
\end{frame}

\begin{frame}
\begin{block}{Determinants of a $n \by n$ Matrix}
For a $n \by n$ matrix $\mat{A}$, choose any row or column.
\begin{description}
\item<2->[\textbf{Expansion by the $\boldsymbol{i}$th row:}]
\begin{equation*}
\abs{\mat{A}} = \sum_{j=1}^{n} a_{ij}C_{ij}
              = \sum_{j=1}^{n} a_{ij}{(-1)}^{(i+j)}\abs{\mat{M_{ij}}}
\end{equation*}
\item<3->[\textbf{Expansion by the $\boldsymbol{j}$th column:}]
\begin{equation*}
\abs{\mat{A}} = \sum_{i=1}^{n} a_{ij}C_{ij}
              = \sum_{i=1}^{n} a_{ij}{(-1)}^{(i+j)}\abs{\mat{M_{ij}}}
\end{equation*}
\end{description}
\end{block}
\onslide<4->
\begin{block}{}
I recommend expanding across the first row.
\end{block}
\end{frame}

\begin{frame}
\begin{example}
Compute the determinant:
\begin{equation*}
\begin{vmatrix}
\+3 & \+1 &  -1 \\
\+2 & \+1 & \+3 \\
\+0 & \+1 & \+2
\end{vmatrix}
\end{equation*}\pause
Expanding across the first row gives:
\begin{equation*}
\begin{split}
\begin{vmatrix}[rrr]
\tikzmarkin<2-4>[hor=style green]{row-a}\tikzmarkin<2>[ver=style green]{col-a}\tikzmarkin<2>[hor=style orange]{end-a}\+3\tikzmarkend{end-a} & \tikzmarkin<3>[ver=style green]{col-b}\tikzmarkin<3>[hor=style orange]{end-b} \+1 \tikzmarkend{end-b}&  \tikzmarkin<4>[ver=style green]{col-c}\tikzmarkin<4>[hor=style orange]{end-c}-1\tikzmarkend{end-c} \tikzmarkend{row-a}\\
\+2 & \+1 & \+3 \\
\+0\tikzmarkend{col-a} & \+1 \tikzmarkend{col-b} & \+2 \tikzmarkend{col-c}
\end{vmatrix}
&= 
\visible<2->{\tikzmarkin<2>[hor=style cyan]{end-aaa} + \tikzmarkend{end-aaa}\  \tikzmarkin<2>[hor=style orange]{end-aa} (+3)\tikzmarkend{end-aa}\begin{vmatrix}1&3\\1&2\end{vmatrix}}
\visible<3->{\tikzmarkin<3>[hor=style cyan]{end-bbb} - \tikzmarkend{end-bbb}\  \tikzmarkin<3>[hor=style orange]{end-bb} (+1) \tikzmarkend{end-bb} \begin{vmatrix}2&3\\0&2\end{vmatrix}} 
\visible<4->{\tikzmarkin<4>[hor=style cyan]{end-ccc} + \tikzmarkend{end-ccc}\ \tikzmarkin<4>[hor=style orange]{end-cc} (-1)\tikzmarkend{end-cc} \begin{vmatrix}2&1\\0&1\end{vmatrix}}\\
\visible<5->{&= 3(1\cdot 2-3\cdot 1) - (2\cdot 2 - 3\cdot 0) - (2\cdot 1 - 1\cdot 0)}\\
\visible<6->{&= -3 - 4 - 2}\\
\visible<7->{&= -9}
\end{split}
\end{equation*}
\end{example}
\end{frame}

\begin{frame}
\begin{block}{Properties of Determinants}
\begin{itemize}[<+- | alert@+>]
\item $\abs{\transposeof{\mat{A}}}=\abs{\mat{A}}$
\item If $\abs{\mat{A}}\neq 0$, then $\mat{A}$ is invertable.
\item If $\abs{\mat{A}}\neq 0$, then $\abs{\inverseof{\mat{A}}}=\dfrac{1}{\abs{\mat{A}}}$
\item If a row (or column) of $\mat{A}$ contains all zeros, then $\abs{\mat{A}}=0$
\item If two rows (or two columns) of $\mat{A}$ are equal, then $\abs{\mat{A}}=0$
\item If $\mat{A}$ is an diagonal, upper triangular, or lower triangular matrix, the determinant is the product of the diagonal elements:
\begin{equation*}
\abs{\mat{A}}=\prod_{i=1}^{m} a_{ii}
\end{equation*}
\end{itemize}
\end{block}
\end{frame}

\begin{frame}
\begin{block}{Cramer's Rule}
Consider the matrix equation:
\begin{equation*}
\mat{A}\vect{x}=\vect{b}\quad \text{where}\quad\abs{\mat{A}}\neq0
\end{equation*}
The matrix $\mat{A_j}$ is obtained by replacing the $j$th column of $\mat{A}$ with $\vect{b}$. 

\vspace{2mm}
The $j$th solution is:
\begin{equation*}
x_j = \dfrac{\abs{\mat{A_j}}}{\abs{\mat{A}}}
\end{equation*}
\end{block}
\end{frame}

\begin{frame}
\begin{example}
Consider the system
\begin{center}
\begin{tabu} to 4cm{*5{X[$r]}}
x & + & 2y & = & 5\\
2x & + & 3y & = & 8
\end{tabu}
\end{center}\pause
Let us solve this system using Cramer's Rule.

This means we need to calculate the following determinats.
\begin{center}
\begin{tabu}{*3{X[$c]}}
\abs{\mat{A}}=
\begin{vmatrix}
1 & 2 \\
2 & 3
\end{vmatrix}\visible<3->{=-1}
&
\abs{\mat{A_x}}=
\begin{vmatrix}
5 & 2 \\
8 & 3
\end{vmatrix}\visible<4->{=-1}
&
\abs{\mat{A_y}}=
\begin{vmatrix}
1 & 5 \\
2 & 8
\end{vmatrix}\visible<5->{=-2}\\
\end{tabu}
\end{center}
\onslide<6->
We can now find $x$ \visible<9->{and $y$}
\begin{equation*}
\visible<6->{x=\dfrac{\abs{\mat{A_x}}}{\abs{\mat{A}}}\visible<7->{=\dfrac{-1}{-1}\visible<8->{=1}}}
\qquad
\visible<9->{y=\dfrac{\abs{\mat{A_y}}}{\abs{\mat{A}}}\visible<10->{=\dfrac{-2}{-1}\visible<11->{=2}}}
\end{equation*}
\end{example}
\end{frame}

\begin{frame}[fragile]
\begin{example}
The \textbf{line of best fit} is the line that gets \quotetext{closest} to every point.

\begin{multistepslide}
\begin{center}
\begin{asy}
size(200);
draw_approx(0, false);
\end{asy}
\end{center}
\nextstep
\begin{center}
\begin{asy}
size(200);
draw_approx(1, false);
\end{asy}
\end{center}
\end{multistepslide}
\end{example}
\end{frame}

\begin{frame}
\begin{block}{Least Squares Approximation}
A general strategy for finding the line $y=mx+b$ that best describes a data set is to find $b$ and $m$ that minimizes the sums of the squares of the vertical distances between the data points and the line, given by $F(b,m)$
\begin{equation*}
F(b,m)=\sum\limits_{i=1}^{n}{\left(y_i-(b+mx_i)\right)}^2
\end{equation*}\pause
To find such a $b$ and $m$, we need to solve the system:
\begin{equation*}
\dfrac{\partial F}{\partial b}=0
\quad\text{and}\quad
\dfrac{\partial F}{\partial m}=0
\end{equation*}
\end{block}
\end{frame}

\begin{frame}
\begin{block}{Least Squares Method}
The best-fit straight line for $n$ data points $(x_i, y_i)$, $i=1,2,\dots,n$, has y-intercept $b$ and slope $m$ as determined by the system
\begin{equation*}
\begin{bmatrix}[ll]
\sum\limits_{i=1}^n 1   & \sum\limits_{i=1}^n x_i   \\
\sum\limits_{i=1}^n x_i & \sum\limits_{i=1}^n x_i^2
\end{bmatrix}
\begin{bmatrix}
b \\
m
\end{bmatrix}
=
\begin{bmatrix}[l]
\sum\limits_{i=1}^n y_i \\
\sum\limits_{i=1}^n x_i y_i
\end{bmatrix}
\end{equation*}
\end{block}
\end{frame}

\begin{frame}[fragile]
\begin{example}
Consider the data comparing the high school and college GPA for four students.

\begin{figure}[!tbp]
\begin{subfigure}[b]{0.3\textwidth}
\begin{tabular}{c|c|c}
$\boldsymbol{i}$ & $\boldsymbol{x_i}$ & $\boldsymbol{y_i}$ \\
\hline
1 & 1.7 & 1.1 \\
2 & 2.3 & 3.1 \\
3 & 3.1 & 2.3 \\
4 & 4.0 & 3.8
\end{tabular}
\vspace{5mm}

\vspace{0.25cm}
%\caption{Picture 1}
\end{subfigure}
%
\begin{subfigure}[b]{0.3\textwidth}
\begin{overprint}
\onslide<1-3>
\begin{asy}
import graph;
import fontsize;
defaultpen(fontsize(9pt));
size(100);
real a=0.746429;
real b=0.565357;
real f(real x) {return a*x+b;}
real min_x=0, max_x=4;
real min_y=0, max_y=4;

// draw data points

dot((1.7,1.1),black);
dot((2.3,3.1),black);
dot((3.1,2.3),black);
dot((4.0,3.8),black);

// linear best-fit
//draw(graph(f,min_x,max_x),red+1bp);

//limits((min_x-0.1,min_y-0.1),(max_x+0.1,max_y+0.1),Crop);

for(real gx=min_x; gx<=max_x; gx+=0.5)
	draw((gx,min_y)--(gx,max_y),dotted+darkgray);
    
for(real gy=min_y; gy<=max_y; gy+=0.5)
	draw((min_y,gy)--(max_x,gy),dotted+darkgray); 

xaxis(YEquals(min_y),min_x,max_x,LeftTicks(NoZero));
//xaxis(YEquals(min_y),min_x,max_x);
yaxis(XEquals(min_x),min_y,max_y,RightTicks(NoZero));
//yaxis(XEquals(min_x),min_y,max_y);
\end{asy}
\onslide<4->
\begin{asy}
import graph;
import fontsize;
defaultpen(fontsize(9pt));
size(100);
real a=0.92;
real b=0.023;
real f(real x) {return a*x+b;}
real min_x=0, max_x=4;
real min_y=0, max_y=4;

// draw data points

dot((1.7,1.1),black);
dot((2.3,3.1),black);
dot((3.1,2.3),black);
dot((4.0,3.8),black);

// linear best-fit
draw(graph(f,min_x,max_x),red+1bp);

//limits((min_x-0.1,min_y-0.1),(max_x+0.1,max_y+0.1),Crop);

for(real gx=min_x; gx<=max_x; gx+=0.5)
	draw((gx,min_y)--(gx,max_y),dotted+darkgray);
    
for(real gy=min_y; gy<=max_y; gy+=0.5)
	draw((min_y,gy)--(max_x,gy),dotted+darkgray); 

xaxis(YEquals(min_y),min_x,max_x,LeftTicks(NoZero));
//xaxis(YEquals(min_y),min_x,max_x);
yaxis(XEquals(min_x),min_y,max_y,RightTicks(NoZero));
//yaxis(XEquals(min_x),min_y,max_y);
\end{asy}
\end{overprint}
%\caption{Picture 2}
\end{subfigure}
\end{figure}\pause

The Least Squares Method system for this dataset is:
\begin{equation*}
\begin{bmatrix}
4    & 11.1  \\
11.1 & 33.79 \\
\end{bmatrix}
\begin{bmatrix}
b \\
m \\
\end{bmatrix}
=
\begin{bmatrix}
10.3  \\
31.33 \\
\end{bmatrix}
\pause\quad\Rightarrow\quad
\begin{bmatrix}
b \\
m \\
\end{bmatrix}
=
\begin{bmatrix}
0.023 \\
0.92  \\
\end{bmatrix}
\end{equation*}\pause
So, the line of best fit is $y=0.92x+0.023$.
\end{example}
\end{frame}

\begin{frame}[fragile]
\begin{example}
Let us consider some nonlinear approximations.

\begin{multistepslide}
\begin{center}
\begin{asy}
size(200);
draw_approx(1);
\end{asy}
\end{center}
\nextstep
\begin{center}
\begin{asy}
size(200);
draw_approx(2);
\end{asy}
\end{center}
\nextstep
\begin{center}
\begin{asy}
size(200);
draw_approx(3);
\end{asy}
\end{center}
\nextstep
\begin{center}
\begin{asy}
size(200);
draw_approx(4);
\end{asy}
\end{center}
\end{multistepslide}
\end{example}
\end{frame}
\end{document}
