\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{slide_helper}
\usepackage[inline]{asymptote}
\usepackage{asy_helper}
\usepackage[super]{nth}
\usepackage{array}
\usepackage{wasysym}
\usepackage{pgfplots}
\pgfplotsset{compat=1.5} 
\usepgfplotslibrary{statistics}

\DeclareSymbolFont{extraup}{U}{zavm}{m}{n}
\DeclareMathSymbol{\varheart}{\mathalpha}{extraup}{86}
\DeclareMathSymbol{\vardiamond}{\mathalpha}{extraup}{87}
\DeclareMathSymbol{\varclub}{\mathalpha}{extraup}{84} 
\DeclareMathSymbol{\varspade}{\mathalpha}{extraup}{85}

\newcommand{\suitheart}[1][]{{\color{red}\text{#1}\varheart}}
\newcommand{\suitspade}[1][]{{\color{black}\text{#1}\spadesuit}}
\newcommand{\suitdiamond}[1][]{{\color{red}\text{#1}\vardiamond}}
\newcommand{\suitclub}[1][]{{\color{black}\text{#1}\varclub}}

\newcommand{\prob}[1]{P\left(#1\right)}
\newcommand{\condprob}[2]{\prob{#1~\middle|~#2}}
\newcommand{\comb}[2]{{_{#1}C_{#2}}}
\newcommand{\perm}[2]{_{#1}P_{#2}}

\newcommand{\nullhypothesis}[1]{H_0&:~{#1}}
\newcommand{\althypothesis}[1]{H_A&:~{#1}}

\begin{asydef}
real nd_func(real mu, real sigma, real x) { return 1/sqrt(2*pi*sigma*sigma)*exp((-1*(x-mu)*(x-mu))/(2*sigma*sigma)); }

guide normal_dist(real mu, real sigma, real xmin, real xmax)
{
	real f(real x) { return nd_func(mu, sigma, x); }
	return graph(f, xmin, xmax);
}

void shade_between(real mu, real sigma, real a, real b, pen p=orange)
{
	real f(real x) { return nd_func(mu, sigma, x); }
	guide g = graph(f, a, b);
	
	filldraw((a,0) -- g -- (b,0) -- cycle, p, black);
}

void multiple_nd_curves_example(real std_dev)
{
	size(300, 190, IgnoreAspect);
    
    draw(normal_dist(0, std_dev, -6,6));
    shade_between(0,std_dev,-std_dev,std_dev);
    draw((0,0)--(0,0.45));
    
    label("$\sigma="+format("%#.2f", std_dev)+"$", (-4.2,0.45), Fill(paleyellow));
    
    xaxis(Bottom(), RightTicks(new real[] {-6,-4,-2,0,2,4,6}));
    yaxis(Left(), LeftTicks(size=nan),ymin = 0, ymax = 0.5);
}
\end{asydef}

\begin{asydef}
pair crit = (150, 33);
real a=-1.25;
real b=1.25;
\end{asydef}

\title[MA205 - Section 10.2]{Regression}

\begin{document}
\begin{frame}
\titlepage
\end{frame}

\begin{frame}
\begin{block}{Recall}
Recall that a linear equation (a straight line) is one that can be written as
\begin{equation*}
y=mx+b
\end{equation*}
where $m$ is the slope (\textquote{rise over run}) and $b$ is the y-intercept.
\end{block}\pause

\begin{definition}
Given a collection of paired sample data, the \textbf{regression line} (or \textbf{line of best fit}) is the straight line that \textquote{best} fits the scatter plot of the data. (We will discuss that \textquote{best} means later.)
\end{definition}
\end{frame}

\begin{frame}
\begin{definition}
The \textbf{regression equation} is 
\begin{equation*}
\hat{y}=b_0+b_1 x
\end{equation*}
 algebraically describes the regression line. The regression equation expresses a relationship between $x$ and $\hat{y}$.
\end{definition}\pause

\begin{definition}
We call $x$ the \textbf{explanatory variable}, \textbf{predictor variable}, or \textbf{independent variable}.
\end{definition}\pause

\begin{definition}
We call $y$ the \textbf{response variable}, or \textbf{dependent variable}.
\end{definition}
\end{frame}

\begin{frame}
\begin{note}
We don't use $y=mx+b$ because the format $y=b_0+b_1 x$ can easily be expanded in include more variables:
\begin{equation*}
y=b_0+b_1 x_1 + b_2 x_2 + b_3 x_3 + \cdots
\end{equation*}
This is used when performing a multiple regression.
\end{note}
\end{frame}

\begin{frame}
\begin{block}{Requirements}
The requirements for performing a regression are:
\begin{enumerate}
\item The sample of paired data is a random sample of quantitative data.\pause
\item Visual examination of the scatterplot shows that the points approximate a straight-line pattern.\pause
\item Outliers can have a strong effect on the regression equation, so remove any outliers if they are known errors.
\end{enumerate}
\end{block}
\end{frame}

\begin{frame}
\begin{block}{Slope}
The slope of the regression line is
\begin{equation*}
b_1=r\cdot\dfrac{s_y}{s_x}
\end{equation*}
where $r$ is the linear correlation coefficient, $s_y$ is the standard deviation of the $y$ values, and $s_x$ is the standard deviation of the $x$ values.
\end{block}\pause

\begin{block}{$y$-intercept}
The $y$-intercept of the regression line is
\begin{equation*}
b_0=\bar{y}-b_1bar{x}
\end{equation*}
where $\bar{y}$ is the sample mean of $y$ values and $\bar{x}$ is the sample mean of $x$ values.
\end{block}\pause

\begin{note}
Technology will calculate both of these values for you.
\end{note}
\end{frame}
\end{document}